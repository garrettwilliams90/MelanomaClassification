# Identifying Melanoma in Images using Deep Learning

### Author: Garrett Williams - [LinkedIn](https://www.linkedin.com/in/williams-garrett/)

Australia has the highest rate of melanoma per capita among all countries, according to the [World Cancer Research Fund](https://www.wcrf.org/dietandcancer/skin-cancer-statistics/). This results in over [1300 deaths this year](https://www.canceraustralia.gov.au/cancer-types/melanoma/statistics#:~:text=In%202019%2C%20there%20were%201%2C405,843%20males%20and%20472%20females). Some of those deaths could be avoided if Melanoma was detected early on. This project aims to identify Melanoma in images of skin lesions using neural networks, more specifically deep learning tools. The dataset includes over 38,00 images generated by the [International Skin Imaging Collaboration (ISIC)](https://challenge.isic-archive.com/data/). My final model was a pretrained VGG16 neural network with an accuracy of 94% and a recall score of 84%.

![Melanoma?](https://raw.githubusercontent.com/garrettwilliams90/MelanomaClassification/main/Images/sunscreen-question-mark.jpeg) <br>
*Image by [Tatiana Kim](https://www.istockphoto.com/portfolio/TatianaKim?mediatype=photography) via [aad.org](https://www.aad.org/public/everyday-care/sun-protection/sunscreen-patients)*

## Table of Contents

- [Business Understanding](#business-understanding)
- [Data Understanding](#data-understanding)
- [Modeling](#modeling)
- [Evaluation](#evaluation)
- [Conclusion](#conclusion)
- [Future Work](#future-work)
- [Repository Navigation](#repository-navigation)

## Business Understanding

Skin cancer is one of the most common types of cancer in the world. Melanoma, specifically, is responsible for 75% of skin cancer deaths, despite being the least common skin cancer. According to the [World Cancer Research Fund](https://www.wcrf.org/dietandcancer/skin-cancer-statistics/), Australia has the highest rate of Melanoma per capita. [Cancer Australia](https://www.canceraustralia.gov.au/cancer-types/melanoma/statistics) estimates close to 17,000 new cases of Melanoma have been diagnosed in 2021, resulting in over 1,000 deaths this year. 

Unlike other cancers though, skin cancer can be visibly seen. By using image classification tools, my work aims to accurately predict if a skin lesion is malignant or benign. By identifying if the skin has Melanoma early on, lives can be saved. I hope that you, the Australian Department of Health, would use your resources in conjunction with my model to develop and market an app for the benefit of your citizens. Using their mobile phone, they can easily take a picture and recognize whether they need to go to a dermatologist for further diagnosis.

## Data Understanding

The data was created by the [Society for Imaging Informatics in Medicine (SIIM)](https://siim.org/) and [International Skin Imaging Collaboration (ISIC)](https://www.isic-archive.com/#!/topWithHeader/wideContentTop/main). SIIM is the leading healthcare organization for informatics in medical imaging whose mission is to advance medical imaging informatics through education, research, and innovation in a multi-disciplinary community. ISIC is an international effort to improve melanoma diagnosis. The ISIC Archive contains the largest publicly available collection of quality-controlled dermoscopic images of skin lesions. I was able to use the data through the [SIIM-ISIC Melanoma Classification competition](https://www.kaggle.com/c/siim-isic-melanoma-classification/overview) on Kaggle.

The following is the citation of the original dataset under CC BY-NC 4.0:

> The ISIC 2020 Challenge Dataset https://doi.org/10.34970/2020-ds01 (c) by ISDIS, 2020
> 
> Creative Commons Attribution-Non Commercial 4.0 International License.
> 
> The dataset was generated by the International Skin Imaging Collaboration (ISIC) and images are from the following sources: Hospital Clínic de Barcelona, Medical University of Vienna, Memorial Sloan Kettering Cancer Center, Melanoma Institute Australia, Sydney Melanoma Diagnostic Centre, University of Queensland, and the University of Athens Medical School.
> 
> You should have received a copy of the license along with this work.
> 
> If not, see https://creativecommons.org/licenses/by-nc/4.0/legalcode.txt.

One limitation of the dataset is the size of images. Since the images had different sizes and were too large for my code to run, I used resized images, found [here](https://www.kaggle.com/cdeotte/jpeg-melanoma-512x512). Another major limitation of this dataset is how imbalanced the target is. 98% of the over 33,000 images were classified as benign. To combat this imbalance, I added only the malignant images from the 2019 SIIM-ISIC Melanoma Classification competition, found [here](https://www.kaggle.com/cdeotte/jpeg-isic2019-512x512), and the malignant images that weren't used in the 2019 or 2020 competitions, found [here](https://www.kaggle.com/cdeotte/malignant-v2-512x512). Since the images came from the same source, [ISIC](https://challenge.isic-archive.com/data/), and there was no fundamental difference between the way they were taken, I'm not worried about creating a bias toward these newly added malignant images.

The final dataset after combining the 3 had over 38,000 images. As a baseline understanding. 85.1% of the validation images are benign and 14.9% of the validation images are malignant. This means that the model's accuracy would be 85% if it always predicted 'Benign'. All code was run using Kaggle and can be found [here](https://www.kaggle.com/garrettwilliams90/code).

![Benign Skin Lesions](https://raw.githubusercontent.com/garrettwilliams90/MelanomaClassification/main/Images/Examples-of-benign-skin-lesions.png)

![Malignant Skin Lesions](https://raw.githubusercontent.com/garrettwilliams90/MelanomaClassification/main/Images/Examples-of-malignant-skin-lesions.png)

## Modeling

I ran 6 different models, fitting to the training set and evaluating on the validation set:
- Simple Baseline Model
- Convolutional Neural Network
- Convolutional Neural Network with Dropout Layers
- Pretrained VGG16
- Pretrained ResNet50
- Pretrained InceptionResNetV2

The key metrics I focused on were Accuracy, Recall, and AUC-ROC. I focused on Recall because having False Negatives are more costly than having False Positives. False Negatives is having a malignant skin lesion but predicting that it's benign. This would result in people thinking they're healthy when they aren't, which could result in lives being lost. False Positives on the other hand are benign lesions being classified as malignant. This would result in people seeing a Dermatologist when they don't need to. This could make it a lot harder for someone who needs to see a doctor to book an appointment. It could also lead to an unnecessary amount of money being spent to visit the Dermatologist when you don't need to.

## Evaluation

The final model will be the VGG16 because it predicted the highest accuracy and recall score, while not overfitting too much to the training data. Again, recall is the second evaluation metric because a low score would mean our model is predicting a skin lesion is benign when it's actually malignant. This implies you're healthy when you actually aren't and need to seek medical assistance. Now, I'll take our VGG16 model and evaluate it on the testing set, which I held out at the beginning. This is so I can truly evaluate our model on unseen images.

![Confusion Matrix](https://raw.githubusercontent.com/garrettwilliams90/MelanomaClassification/main/Images/final-model-confusion-matrix.png)

![Metrics](https://raw.githubusercontent.com/garrettwilliams90/MelanomaClassification/main/Images/final-model-metrics.png)

My model accurately predicts the diagnosis of a skin lesion 93.8% of the time and incorrectly labels the lesion as benign 16.3% of the time. As a reminder, my baseline understanding had an accuracy of 85.1% and a recall score of 0.

## Conclusion

The Australian Department of Health can develop and market a mobile app for the public that uses my model to classify if a person has melanoma or not. This would result in quicker reactions to seek out professionally-trained Dermatologists, which could save lives. 

## Future Work

I started working on some future steps but didn't have time to include everything in this final summary notebook. To combat class imbalance, I trained a VGG16 model with `class_weight="balanced"` in this [Kaggle notebook](https://www.kaggle.com/garrettwilliams90/vgg16-model-with-balanced-class-weight), also found on [GitHub](https://github.com/garrettwilliams90/MelanomaClassification/blob/main/Notebooks/Future_Work/vgg16-model-with-balanced-class-weight.ipynb). I then evaluated that model in this [Kaggle notebook](https://www.kaggle.com/garrettwilliams90/evaluate-7-vgg16-with-balanced-class-weights) which can also be found on [GitHub](https://github.com/garrettwilliams90/MelanomaClassification/blob/main/Notebooks/Future_Work/evaluate-7-vgg16-with-balanced-class-weights.ipynb). The 3rd and final notebook in my Future Work folder contains some preliminary work on what would happen if I resized the images to 64x64 instead of 128x128. You can look at my test notebook on [Kaggle](https://www.kaggle.com/garrettwilliams90/testing-vgg16-model-on-64pixel-images) or [Github](https://github.com/garrettwilliams90/MelanomaClassification/blob/main/Notebooks/Future_Work/testing-vgg16-model-on-64pixel-images.ipynb).

## Repository Navigation

Notebooks
- All notebooks were run using Kaggle and can be found [here](https://www.kaggle.com/garrettwilliams90/code).
- My final notebook specifically can be found [here on Kaggle](https://www.kaggle.com/garrettwilliams90/melanoma-classification-final-notebook) or [here on Github](https://github.com/garrettwilliams90/MelanomaClassification/blob/main/melanoma-classification-summary.ipynb)

Data
- Orignal Data can be found [here on Kaggle](https://www.kaggle.com/c/siim-isic-melanoma-classification/overview) or [here on the ISIC Archives](https://challenge2020.isic-archive.com/)
- The 3 datasets that were reformatted by Chris Deotte can be found [here](https://www.kaggle.com/cdeotte/jpeg-melanoma-512x512), [here](https://www.kaggle.com/cdeotte/jpeg-isic2019-512x512), and [here](https://www.kaggle.com/cdeotte/malignant-v2-512x512).

Presentation
- A pdf of the presentation slides can be found [here](https://github.com/garrettwilliams90/MelanomaClassification/blob/main/presentation.pdf)
```
├── Images                                                            <--images used in README                                                          
├── Notebooks
│    ├── Future_Work
│         ├── evaluate-7-vgg16-with-balanced-class-weights.ipynb      <--preliminary evaluation for model with class_weight='balanced'
│         ├── testing-vgg16-model-on-64pixel-images.ipynb             <--preliminary work on smaller images 
│         └── vgg16-model-with-balanced-class-weight.ipynb            <--preliminary work on model with class_weight='balanced'
│    ├── Model_Evaluations
│         ├── evaluate-1-baseline-and-2-first-cnn-model.ipynb         <--evaluations for 1st and 2nd iterations
│         ├── evaluate-3-second-cnn-model-and-4-vgg16-model.ipynb     <--evaluations for 3rd and 4th iterations
│         └── evaluate-5-resnet50-and-6-inceptionresnet-model.ipynb   <--evaluations for 5th and 6th iterations
│    ├── Model_Iterations
│         ├── baseline-model.ipynb                                    <--1st model iteration
│         ├── first-cnn-model.ipynb                                   <--2nd model iteration
│         ├── inceptionresnetv2-model.ipynb                           <--6th model iteration
│         ├── resnet50-model.ipynb                                    <--5th model iteration
│         ├── second-cnn-model.ipynb                                  <--3rd model iteration
│         └── vgg16-model.ipynb                                       <--4th model iteration
│    └── eda-and-data-preprocessing.ipynb
├── .gitignore                                                        <--files to be ignored
├── README.md
├── final_model.h5                                                    <--keras file for final model
├── melanoma-classification-summary.ipynb                             <--summary notebook
├── presentation.pdf                                                  <--presentation slides
└── requirements.txt                                                  <--package versions on kaggle's environment
```
